{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import libraries needed,\n",
    "import IPython\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the data using pandas,\n",
    "data = pd.read_csv(\"C://Users//user//Desktop//ProjetAI//diabetic_data.csv\")\n",
    "print(data.shape)\n",
    "\n",
    "#Exploring the data further,\n",
    "print(data.info())\n",
    "print(data.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let's see how the data looks like,\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling to make it fit for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dealing with missing values,\n",
    "\n",
    "datacopy = data.copy() \n",
    "Rep = datacopy.replace('?', np.NaN) \n",
    "nacheck = Rep.isnull().sum() \n",
    "nacheck\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#De ce qui précède, nous pouvons voir que \"Weight, payer_code et medical_specialty\" ont beaucoup de valeurs manquantes,\n",
    "#c'est mieux donc de supprimer ces valeurs de dataset !\n",
    "\n",
    "#supprimer ces colonnes\n",
    "\n",
    "datacopy= datacopy.drop(['weight','payer_code','medical_specialty'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacopy['readmitted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on peur voir qu'il y a 3 types de valeurs :- 'NO','<30','>30'. donc, to make it a categorical variable so that different  \n",
    "# ML techniques can be applies.\n",
    "\n",
    "datacopy['30readmit'] = np.where(datacopy['readmitted'] == 'NO', 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacopy.groupby('30readmit').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des patients morts de l'ensemble de données.\n",
    "\n",
    "datacopy = datacopy[((datacopy.discharge_disposition_id != 11) & \n",
    "                                          (datacopy.discharge_disposition_id != 13) &\n",
    "                                          (datacopy.discharge_disposition_id != 14) & \n",
    "                                          (datacopy.discharge_disposition_id != 19) & \n",
    "                                          (datacopy.discharge_disposition_id != 20) & \n",
    "                                          (datacopy.discharge_disposition_id != 21))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacopy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exécution d'une analyse exploratoire des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voyons la relation entre les différentes variables pour comprendre les données et s'il existe une forte corrélation \n",
    "# entre deux variables alors nous pouvons considérer l'une d'entre elles.\n",
    "import seaborn as sns\n",
    "#Seaborn is a Python data visualization library based on matplotlib. \n",
    "#It provides a high-level interface for drawing attractive and informative statistical graphics.\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "sm = scatter_matrix(datacopy[['num_procedures', 'num_medications', 'number_emergency']], figsize = (8, 8))\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we can see that there is no problem of multi-collinearity.\n",
    "We can also see that as the number_emergency increases the num_medication decreases. \n",
    "\n",
    "In statistics, multicollinearity (also collinearity) is a phenomenon in which one predictor variable in a multiple regression model can be linearly predicted from the others with a substantial degree of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's try to see how the age and number of medicines vary,\n",
    "sortage = datacopy.sort_values(by = 'age')\n",
    "x = sns.stripplot(x = \"age\", y = \"num_medications\", data = sortage, color = 'red')\n",
    "sns.despine() #remove top and right axes\n",
    "x.figure.set_size_inches(10, 6)\n",
    "x.set_xlabel('Age')\n",
    "x.set_ylabel('Number of Medications')\n",
    "x.axes.set_title('Number of Medications vs. Age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gender and Readmissions,\n",
    "plot1 = sns.countplot(x = 'gender', hue = '30readmit', data = datacopy) \n",
    "\n",
    "sns.despine()\n",
    "plot1.figure.set_size_inches(7, 6.5)\n",
    "plot1.legend(title = 'Readmitted patients', labels = ('No', 'Yes'))\n",
    "plot1.axes.set_title('Readmissions Balance by Gender')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Relation between age and readmission,\n",
    "\n",
    "b = datacopy.age.unique()\n",
    "b.sort()\n",
    "b_sort = np.array(b).tolist()\n",
    "\n",
    "\n",
    "ageplt = sns.countplot(x = 'age', hue = '30readmit', data = datacopy, order = b_sort) \n",
    "\n",
    "sns.despine()\n",
    "ageplt.figure.set_size_inches(7, 6.5)\n",
    "ageplt.legend(title = 'Readmitted within 30 days', labels = ('No', 'Yes'))\n",
    "ageplt.axes.set_title('Readmissions Balance by Age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the numerical variables in our dataset,\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "datacopy.hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exploring the categorical variables,\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,10), ncols=2, nrows=2)\n",
    "\n",
    "sns.countplot(x=\"readmitted\", data=datacopy, ax=ax[0][0])\n",
    "sns.countplot(x=\"race\", data=datacopy, ax=ax[0][1])\n",
    "sns.countplot(x=\"gender\", data=datacopy, ax=ax[1][0])\n",
    "sns.countplot(x=\"age\", data=datacopy, ax=ax[1][1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prédiction à l'aide de modèles ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant d'appliquer la régression logistique, nous devrons adapter les données pour effectuer la régression logistique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nettoyage des données, remplacement des valeurs nulles des données numériques par 0 et des données d'objet par inconnu,\n",
    "\n",
    "numcolumn = datacopy.select_dtypes(include = [np.number]).columns\n",
    "objcolumn = datacopy.select_dtypes(include = ['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substituting 0 and unknown,\n",
    "\n",
    "datacopy[numcolumn] = datacopy[numcolumn].fillna(0)\n",
    "datacopy[objcolumn] = datacopy[objcolumn].fillna(\"unknown\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacopy.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding the data,\n",
    "\n",
    "def map_now():\n",
    "    listname = [('infections', 139),\n",
    "                ('neoplasms', (239 - 139)),\n",
    "                ('endocrine', (279 - 239)),\n",
    "                ('blood', (289 - 279)),\n",
    "                ('mental', (319 - 289)),\n",
    "                ('nervous', (359 - 319)),\n",
    "                ('sense', (389 - 359)),\n",
    "                ('circulatory', (459-389)),\n",
    "                ('respiratory', (519-459)),\n",
    "                ('digestive', (579 - 519)),\n",
    "                ('genitourinary', (629 - 579)),\n",
    "                ('pregnancy', (679 - 629)),\n",
    "                ('skin', (709 - 679)),\n",
    "                ('musculoskeletal', (739 - 709)),\n",
    "                ('congenital', (759 - 739)),\n",
    "                ('perinatal', (779 - 759)),\n",
    "                ('ill-defined', (799 - 779)),\n",
    "                ('injury', (999 - 799))]\n",
    "    \n",
    "    \n",
    "    dictcout = {}\n",
    "    count = 1\n",
    "    for name, num in listname:\n",
    "        for i in range(num):\n",
    "            dictcout.update({str(count): name})  \n",
    "            count += 1\n",
    "    return dictcout\n",
    "  \n",
    "\n",
    "def codemap(df, codes):\n",
    "    import pandas as pd\n",
    "    namecol = df.columns.tolist()\n",
    "    for col in namecol:\n",
    "        temp = [] \n",
    "        for num in df[col]:           \n",
    "            if ((num is None) | (num in ['unknown', '?']) | (pd.isnull(num))): temp.append('unknown')\n",
    "            elif(num.upper()[0] == 'V'): temp.append('supplemental')\n",
    "            elif(num.upper()[0] == 'E'): temp.append('injury')\n",
    "            else: \n",
    "                lkup = num.split('.')[0]\n",
    "                temp.append(codes[lkup])           \n",
    "        df.loc[:, col] = temp               \n",
    "    return df \n",
    "\n",
    "\n",
    "listcol = ['diag_1', 'diag_2', 'diag_3']\n",
    "codes = map_now()\n",
    "datacopy[listcol] = codemap(datacopy[listcol], codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's look at the dataset again and drop the irrelevant columns,\n",
    "\n",
    "datacopy.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = datacopy.drop(['encounter_id', \"patient_nbr\", 'admission_type_id','readmitted'], axis =1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listnormal = ['time_in_hospital', 'num_lab_procedures', 'num_procedures', 'num_medications',\n",
    "                     'number_outpatient', 'number_emergency', 'number_inpatient', 'number_diagnoses']\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "normal = StandardScaler()\n",
    "\n",
    "data1[listnormal] = normal.fit_transform(data1[listnormal])\n",
    "\n",
    "data1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's store readmitted in y and rest of the columns in X,\n",
    "\n",
    "Y = data1['30readmit']\n",
    "X = data1.drop(['30readmit'], axis =1)\n",
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Splitting the data into training and vallidation data sets. The training data will contain 80 % of the data and validation will contain remaining 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size = .2, \n",
    "                                                random_state = 7, stratify = Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"shape of Xtrain,Xtest:\",Xtrain.shape,Xtest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# créer un modèle logistique comme régression logistique à l'aide de Sklearn\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logisticreg = LogisticRegression(tol=1e-7, penalty='l2', C=0.0005)\n",
    "logisticreg.fit(Xtrain, Ytrain)\n",
    "Ylog = logisticreg.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Vérification de la précision (accuracy) du modèle\n",
    "\n",
    "print(\" The accuracy of the Logistic regression model:\" ,logisticreg.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vérification de la matrice de confusion\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(Ytest, Ylog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(confusion_matrix(Ytest, Ylog), annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "all_sample_title = 'Accuracy Score: {0}'.format(logisticreg.score(Xtest, Ytest))\n",
    "plt.title(all_sample_title, size = 15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification du résumé de la classification\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Ytest, Ylog, target_names = ['NO', 'YES']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the performance of model using ROC curve plots\n",
    "YScre = logisticreg.decision_function(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Computing false and true positive rates\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr,_=roc_curve(logisticreg.predict(Xtrain),Ytrain,drop_intermediate=False)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "##Creating the ROC,\n",
    "plt.plot(fpr, tpr, color='blue',\n",
    " lw=2, label='ROC curve')\n",
    "##Finding FPR and TPR,\n",
    "plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')\n",
    "##Splecifying the label and title,\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### As seen from the above, the performance of our model is average, not too great. So, let's go ahead and see other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=42,n_estimators=500)\n",
    "random_forest.fit(Xtrain, Ytrain)\n",
    "Yrandforest = random_forest.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the score,\n",
    "scorey =random_forest.predict_proba(Xtest)[:,1]\n",
    "rfpr, rtpr, thresholds = roc_curve(Ytest, scorey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the accuracy,\n",
    "\n",
    "print(\" Accuracy of Randomeforest classification: \", random_forest.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing the confusion matrix,\n",
    "print(confusion_matrix(Ytest, Yrandforest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(confusion_matrix(Ytest, Yrandforest), annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Reds_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "all_sample_title = 'Accuracy Score: {0}'.format(random_forest.score(Xtest, Ytest))\n",
    "plt.title(all_sample_title, size = 15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Ytest, Yrandforest, target_names = ['NO', 'YES']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determining which features are most important,\n",
    "feature_names = Xtrain.columns\n",
    "feature_imports = random_forest.feature_importances_\n",
    "most_imp_features = pd.DataFrame([f for f in zip(feature_names,feature_imports)], columns=[\"Feature\", \"Importance\"]).nlargest(10, \"Importance\")\n",
    "most_imp_features.sort_values(by=\"Importance\", inplace=True)\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(range(len(most_imp_features)), most_imp_features.Importance, align='center', alpha=0.8)\n",
    "plt.yticks(range(len(most_imp_features)), most_imp_features.Feature, fontsize=14)\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Most important features - Random Forest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoosted Classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a AdaBoosted Classification model,\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "adaclass = AdaBoostClassifier(n_estimators = 20, learning_rate = 0.2, random_state = 123)\n",
    "adaclass.fit(Xtrain, Ytrain)\n",
    "yadaclas = adaclass.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The accurary of AdaBoosted Classification model: \", adaclass.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the confusion matrix,\n",
    "print(confusion_matrix(Ytest, yadaclas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(confusion_matrix(Ytest, yadaclas), annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Greens_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "all_sample_title = 'Accuracy Score: {0}'.format(adaclass.score(Xtest, Ytest))\n",
    "plt.title(all_sample_title, size = 15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking recall, f1 :-\n",
    "print(classification_report(Ytest, yadaclas, target_names = ['NO', 'YES']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the False Positive and True Positive rate to get the ROC curve  \n",
    "yadaclas = adaclass.decision_function(Xtest)\n",
    "fpr_adaclass, tpr_adaclass, thresholds = roc_curve(Ytest, yadaclas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The accuracy can be improved by tuning the model, so let's do that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters Tunning for AdaBoosted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing parameter tuning,\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "ada_boost = AdaBoostClassifier(n_estimators = 20, learning_rate = 0.2, random_state = 123)\n",
    "gridparam ={\n",
    "        'n_estimators': [100, 200,500],\n",
    "        'learning_rate': [0.2,0.5,1.0],\n",
    "},\n",
    "adagrid = GridSearchCV(ada_boost, cv=3, n_jobs=3, param_grid=gridparam)\n",
    "adagrid.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The accuracy of the model with the best parameters\n",
    "adagrid.score(Xtest, Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridyada = adagrid.predict(Xtest)\n",
    "print(classification_report(Ytest, gridyada, target_names = ['NO', 'YES']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ygridadascore = adagrid.decision_function(Xtest)\n",
    "fpr_adamod, tpr_adamod, thresholds_grid_ada = roc_curve(Ytest, ygridadascore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfgini = DecisionTreeClassifier(criterion = \"gini\", random_state = 100,\n",
    "                               max_depth=3, min_samples_leaf=5)\n",
    "clfgini.fit(Xtrain, Ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypreddt = clfgini.predict(Xtest)\n",
    "ypreddt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"Accuracy is \", accuracy_score(Ytest,ypreddt)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_log, tpr_log, thresholds = roc_curve(Ytest, YScre)#logistic regression\n",
    "fpr_rf, tpr_rf, thresholds = roc_curve(Ytest, Yrandforest)#random forest classifier\n",
    "fpr_adaclf, tpr_adaclf, thresholds = roc_curve(Ytest, yadaclas)#Ada boost classifier\n",
    "fpr_adamod, tpr_adamod, thresholds = roc_curve(Ytest,ygridadascore )#Hyperparameters Tunning for AdaBoosted\n",
    "fpr_dt, tpr_dt, thresholds = roc_curve(Ytest,ypreddt )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare the ROC curve between different models\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(fpr_log, tpr_log, label='Logistic regression')\n",
    "plt.plot(fpr_adaclf, tpr_adaclf, label='Adaboost Classifier')\n",
    "plt.plot(fpr_rf, tpr_rf, label='Randomforest Classifier')\n",
    "plt.plot(fpr_adamod, tpr_adamod, label='Adaboost with the best Pars')\n",
    "plt.plot(fpr_dt, tpr_dt, label='Decision Tree')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "         label='random', alpha=.8)\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "plt.xticks(np.arange(0,1.1,0.1))\n",
    "plt.yticks(np.arange(0,1.1,0.1))\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.axes().set_aspect('equal')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Accuracy of Logistic regression model:\" ,logisticreg.score(Xtest, Ytest)*100)\n",
    "print(\"Accuracy of Random forest classification: \", random_forest.score(Xtest, Ytest)*100)\n",
    "print(\"Accuracy of AdaBoosted Classification model: \", adaclass.score(Xtest, Ytest)*100)\n",
    "print(\"Accuracy of Hyperparameter Tuning AdaBoosted Classification model: \", adagrid.score(Xtest, Ytest)*100)\n",
    "print( \"Accuracy of Decision Tree \", accuracy_score(Ytest,ypreddt)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. From the above we can see that the accuracy levels of AdaBoost after tuning and Random forest is among the best, about 64%.\n",
    "2. The accuracy of all the models are similar and ranges between 62-64%. Further, applying more pre-processing techniques\n",
    "   might help. The dataset needs more data cleaning and data fitting to achieve a higher degree of accuracy.\n",
    "3. Looking at the false positives and the recall value which is approx 60% in Random forest, it gives us better results than        the rest.\n",
    "4. The above visual helps us in seeing the accuracy and the ROC curver further helps us decide the performance of different        models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
